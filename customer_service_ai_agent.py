# -*- coding: utf-8 -*-
"""Customer_Service_AI_Agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HHteaD1LHNQt321vWlzrOAiCKtNwjSiX
"""

!pip install llama-index
!pip install llama-index-llms-groq
!pip install llama-index-embeddings-huggingface

# Setup Groq LLM connection
from llama_index.llms.groq import Groq
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import Settings
import os
import nest_asyncio

nest_asyncio.apply()

# Get Groq API key from Colab secrets
from google.colab import userdata
groq_api_key = userdata.get('GROQ_API_KEY')

# Setup the LLM with Groq - Using a valid Groq model
Settings.llm = Groq(
    model="meta-llama/llama-4-scout-17b-16e-instruct",
    api_key=groq_api_key,
)

# Setup the embedding model with SentenceTransformers
Settings.embed_model = HuggingFaceEmbedding(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

from typing import List
from llama_index.core import SimpleDirectoryReader
from llama_index.core.node_parser import SentenceSplitter
from llama_index.core import VectorStoreIndex
from llama_index.core.tools import QueryEngineTool

#-------------------------------------------------------------
# Tool 1 : Function that returns the list of items in an order
#-------------------------------------------------------------
def get_order_items(order_id: int) -> List[str]:
    """Given an order Id, this function returns the
    list of items purchased for that order"""

    order_items = {
        1001: ["Laptop", "Mouse"],
        1002: ["Keyboard", "HDMI Cable"],
        1003: ["Laptop", "Keyboard"]
    }
    if order_id in order_items.keys():
        return order_items[order_id]
    else:
        return []

#-------------------------------------------------------------
# Tool 2 : Function that returns the delivery date for an order
#-------------------------------------------------------------
def get_delivery_date(order_id: int) -> str:
    """Given an order Id, this function returns the
    delivery date for that order"""

    delivery_dates = {
        1001: "10-Jun",
        1002: "12-Jun",
        1003: "08-Jun"
    }
    if order_id in delivery_dates.keys():
        return delivery_dates[order_id]
    else:
        return "No delivery date found"  # Changed from [] to string

#----------------------------------------------------------------
# Tool 3 : Function that returns maximum return days for an item
#----------------------------------------------------------------
def get_item_return_days(item: str) -> int:
    """Given an Item, this function returns the return support
    for that order. The return support is in number of days"""

    item_returns = {
        "Laptop": 30,
        "Mouse": 15,
        "Keyboard": 15,
        "HDMI Cable": 5
    }
    if item in item_returns.keys():
        return item_returns[item]
    else:
        # Default
        return 45

#-------------------------------------------------------------
# Tool 4 : Vector DB that contains customer support contacts
#-------------------------------------------------------------
# Setup vector index for return policies
support_docs = SimpleDirectoryReader(input_files=["Customer Service.pdf"]).load_data()

splitter = SentenceSplitter(chunk_size=1024)
support_nodes = splitter.get_nodes_from_documents(support_docs)
support_index = VectorStoreIndex(support_nodes)
support_query_engine = support_index.as_query_engine()

from llama_index.core.tools import FunctionTool

# Create tools for the 3 functions and 1 index
order_item_tool = FunctionTool.from_defaults(fn=get_order_items)
delivery_date_tool = FunctionTool.from_defaults(fn=get_delivery_date)
return_policy_tool = FunctionTool.from_defaults(fn=get_item_return_days)

support_tool = QueryEngineTool.from_defaults(
    query_engine=support_query_engine,
    name="customer_support",
    description=(
        "Customer support policies and contact information. "
        "Use this for general support questions, policies, and contact details."
    ),
)

# CORRECT AGENT SETUP
from llama_index.core.agent import ReActAgent

# Create ReActAgent with direct constructor
agent = ReActAgent(
    tools=[
        order_item_tool,
        delivery_date_tool,
        return_policy_tool,
        support_tool
    ],
    llm=Settings.llm,
    verbose=True,
    system_prompt=(
        "You are a helpful customer service agent. "
        "Use the available tools to help customers with their orders, deliveries, returns, and support questions. "
        "Always be polite and helpful in your responses."
    )
)

import asyncio

async def main():
    answer = await agent.run("What is the return policy for order number 1001?")
    print("\nFinal output:\n", answer)

asyncio.run(main())

import asyncio

async def main():
    answer = await agent.run("What is the return policy for order number 1002?")
    print("\nFinal output:\n", answer)

asyncio.run(main())

# handler = agent.run("What is the return policy for order number 1001?")

# # Try different methods to wait for completion
# try:
#     # Method 1: Try wait()
#     handler.wait()
#     answer = handler.result()
#     print("\nFinal output:\n", answer)
# except AttributeError:
#     try:
#         # Method 2: Try run_to_completion() or similar
#         if hasattr(handler, 'run_to_completion'):
#             handler.run_to_completion()
#         answer = handler.result()
#         print("\nFinal output:\n", answer)
#     except Exception as e:
#         print(f"Error with handler: {e}")
#         print("Available methods:", [method for method in dir(handler) if not method.startswith('_')])

